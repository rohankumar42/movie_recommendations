{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from lmafit import lmafit_mc_adp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INVALID = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(x, y):\n",
    "    assert(x.shape == y.shape)\n",
    "    return np.linalg.norm(x - y) / np.sqrt(x.shape[0])\n",
    "\n",
    "def similarity_matrix_cosine(X):\n",
    "    '''\n",
    "    :param X: Ratings matrix. X[i, j] represents the rating of user i for item j.    \n",
    "    :return: n x n cosine similarity matrix\n",
    "    '''\n",
    "    dist = scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(X, 'cosine'))\n",
    "    return 1 - dist\n",
    "\n",
    "def similarity_matrix_knn(X, k, dim=2):\n",
    "    '''\n",
    "    :param X: Ratings matrix. X[i, j] represents the rating of user i for item j.    \n",
    "    :return: n x n KNN similarity matrix\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    if k > n:\n",
    "        raise IndexError('Only {} points, cannot have {} neighbors'\n",
    "                         .format(n, k))\n",
    "    sim = np.zeros((n, n))\n",
    "    dist = spatial.distance_matrix(X, X, dim)\n",
    "    for i in range(n):\n",
    "        # ind is the indices of the closest k points to point i\n",
    "        ind = np.argpartition(dist[i], -k)[:k]\n",
    "        sim[i, ind] = 1.0 / k\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rating(user_id, movie_id, ratings, sim):\n",
    "    n = ratings.shape[0]\n",
    "    sim_values = sim[user_id, :]\n",
    "    movie_ratings = ratings[:, movie_id]\n",
    "    \n",
    "    # Use only valid ratings\n",
    "    valid_ind = movie_ratings != INVALID\n",
    "    sim_values = sim_values[valid_ind]\n",
    "    movie_ratings = movie_ratings[valid_ind]\n",
    "    pred_rating = sim_values.dot(movie_ratings)\n",
    "    total = sim_values.sum()\n",
    "    return pred_rating / total if total > 0 else pred_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_collaborative_filtering(ratings, p, sim_measure='cosine', k=5, dim=2):\n",
    "    '''\n",
    "    :param ratings: Ratings matrix, where ratings[i][j] represents \n",
    "    user i's rating for movie j.\n",
    "    :param sim_measure: Similarity measure to use\n",
    "    :param p: Fraction of data to use as test-set\n",
    "    :param k: In case of kNN, value of k to use\n",
    "    :param dim: In case of kNN, value of dim to use\n",
    "    \n",
    "    :return: RMSE error of predictions\n",
    "    '''\n",
    "    # Get test indices\n",
    "    valid_ind = np.where(ratings != INVALID)\n",
    "    N = valid_ind[0].shape[0]\n",
    "    test_subset = np.random.choice(np.arange(N), int(p * N), replace=False)\n",
    "    test_ind = valid_ind[0][test_subset], valid_ind[1][test_subset]\n",
    "    num_test = test_subset.shape[0]\n",
    "    \n",
    "    # Make the test indices invalid\n",
    "    train_ratings = np.array(ratings)\n",
    "    train_ratings[test_ind] = INVALID\n",
    "    \n",
    "    # Train on train set\n",
    "    if sim_measure.lower() == 'cosine':\n",
    "        sim = similarity_matrix_cosine(train_ratings)\n",
    "    elif sim_measure.lower() == 'knn':\n",
    "        sim = similarity_matrix_knn(train_ratings, k=k, dim=dim)\n",
    "    else:\n",
    "        raise ValueError('Unknown similarity measure {}'\n",
    "                         .format(sim_measure))\n",
    "    pred_ratings = np.zeros((num_test,))\n",
    "    \n",
    "    # Compute error\n",
    "    true_ratings = ratings[test_ind]\n",
    "    for i, (u, m) in enumerate(zip(*test_ind)):\n",
    "        pred_ratings[i] = get_rating(u, m, train_ratings, sim)\n",
    "    \n",
    "    pred_ratings = pred_ratings.clip(1, 5)\n",
    "    return RMSE(true_ratings, pred_ratings)\n",
    "\n",
    "\n",
    "def test_matrix_completion(ratings, p, k):\n",
    "    '''\n",
    "    :param ratings: Ratings matrix, where ratings[i][j] represents \n",
    "    user i's rating for movie j.\n",
    "    :param p: Fraction of data to use as test-set\n",
    "    :param k: Estimated rank of matrix to use for LMaFit\n",
    "    \n",
    "    :return: RMSE error of predictions\n",
    "    '''\n",
    "    # Get test indices\n",
    "    valid_ind = np.where(ratings != INVALID)\n",
    "    N = valid_ind[0].shape[0]\n",
    "    indices = np.arange(N)\n",
    "    np.random.shuffle(indices)\n",
    "    num_test = int(p * N)\n",
    "    test_ind = valid_ind[0][indices[:num_test]], valid_ind[1][indices[:num_test]]\n",
    "    train_ind = valid_ind[0][indices[num_test:]], valid_ind[1][indices[num_test:]]\n",
    "        \n",
    "    # Make the test indices invalid\n",
    "    train_ratings = np.array(ratings)\n",
    "    train_ratings[test_ind] = INVALID\n",
    "    \n",
    "    # Run LMaFit\n",
    "    a, b, _ = lmafit_mc_adp(ratings.shape[0], ratings.shape[1], k, train_ind, ratings[train_ind], None)\n",
    "    completed = a.dot(b)\n",
    "    \n",
    "    # Compute error\n",
    "    completed = completed.clip(1, 5)\n",
    "    return RMSE(ratings[test_ind], completed[test_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_ratings = np.load('1M_ratings_np.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 1.88 s, total: 1min 55s\n",
      "Wall time: 2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97467607518076849"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_collaborative_filtering(ratings=true_ratings[:, :], p=0.2, sim_measure='cosine', k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.6 s, sys: 11.5 s, total: 1min 6s\n",
      "Wall time: 39.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90755631147466764"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_matrix_completion(ratings=true_ratings[:, :], p=0.5, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "movie_file = \"ml-1m/movies.dat\"\n",
    "m_names = [\"bad_index\", \"Title\", \"Genre\"]\n",
    "movies = pd.read_csv(movie_file, nrows=1000000, header=None, names=m_names, sep=\"::\", engine='python')\n",
    "movie_to_index = dict((m,i) for i,m in zip(movies.index, movies[\"bad_index\"]))\n",
    "movie_to_genre = dict((i,g) for i,g in zip(movies.index, movies[\"Genre\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_to_int = {\n",
    "    'Action' : 0,\n",
    "    'Adventure' : 1,\n",
    "    'Animation' : 2,\n",
    "    'Children\\'s' : 3,\n",
    "    'Comedy' : 4,\n",
    "    'Crime' : 5,\n",
    "    'Documentary' : 6,\n",
    "    'Drama' : 7,\n",
    "    'Fantasy' : 8,\n",
    "    'Film-Noir' : 9, \n",
    "    'Horror' : 10,\n",
    "    'Musical' : 11,\n",
    "    'Mystery' : 12,\n",
    "    'Romance' : 13,\n",
    "    'Sci-Fi' : 14,\n",
    "    'Thriller' : 15,\n",
    "    'War' : 16,\n",
    "    'Western' : 17, \n",
    "}\n",
    "NUM_GENRES = 18\n",
    "\n",
    "def get_genres_for_movie(movie, curr):\n",
    "    inds = [genre_to_int[genre] for genre in movie_to_genre[movie].split('|')]\n",
    "    for i in inds:\n",
    "        curr[i] += 1\n",
    "    return curr\n",
    "\n",
    "def get_top_k_genres_for_user(mat, user, k):\n",
    "    movies = mat[user]\n",
    "    genre_prefs = np.zeros(len(genre_to_int))\n",
    "    average_rating = movies[np.nonzero(movies)].mean()\n",
    "    for i, movie in enumerate(movies):\n",
    "        if movie > average_rating:\n",
    "            genre_prefs = get_genres_for_movie(i, genre_prefs)\n",
    "    return np.flip(np.argsort(genre_prefs), axis=0)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genre_similarity_matrix_by_overlap(X, top_k):\n",
    "    '''\n",
    "    :param X: Ratings matrix. X[i, j] represents the rating of user i for item j.    \n",
    "    :param top_k: Top-k genres will be considered\n",
    "    :return: n x n genre similarity matrix\n",
    "    '''\n",
    "    n = X.shape[0]  # Number of users\n",
    "    genre_ratings = np.zeros((NUM_GENRES, n, n), dtype=np.bool)\n",
    "    for u in range(n):\n",
    "        best_genres = get_top_k_genres_for_user(X, u, top_k)\n",
    "        genre_ratings[best_genres, u, :] = True\n",
    "\n",
    "    # Now, genre_ratings[i, u, :] == True iff user u has genre i in their top-k genres\n",
    "    # overlap_by_genre[i, u, v] == True iff users u and v both have genre i in their top-k genres\n",
    "    overlap_by_genre = np.logical_and(genre_ratings, genre_ratings.transpose((0, 2, 1)))\n",
    "    assert(overlap_by_genre.shape == (NUM_GENRES, n, n))\n",
    "\n",
    "    return overlap_by_genre.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_collaborative_filtering_with_genres(ratings, p, sim_measure='cosine', k=5, dim=2, top_k=3):\n",
    "    '''\n",
    "    :param ratings: Ratings matrix, where ratings[i][j] represents \n",
    "    user i's rating for movie j.\n",
    "    :param sim_measure: Similarity measure to use\n",
    "    :param p: Fraction of data to use as test-set\n",
    "    :param k: In case of kNN, value of k to use\n",
    "    :param dim: In case of kNN, value of dim to use\n",
    "    :param top_k: Top-k genres will be considered\n",
    "    \n",
    "    :return: RMSE error of predictions\n",
    "    '''\n",
    "    # Get test indices\n",
    "    valid_ind = np.where(ratings != INVALID)\n",
    "    N = valid_ind[0].shape[0]\n",
    "    test_subset = np.random.choice(np.arange(N), int(p * N), replace=False)\n",
    "    test_ind = valid_ind[0][test_subset], valid_ind[1][test_subset]\n",
    "    num_test = test_subset.shape[0]\n",
    "    \n",
    "    # Make the test indices invalid\n",
    "    train_ratings = np.array(ratings)\n",
    "    train_ratings[test_ind] = INVALID\n",
    "    \n",
    "    # Compute the genre similarity matrix\n",
    "    genre_sim = genre_similarity_matrix_by_overlap(train_ratings, top_k=top_k)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    if sim_measure.lower() == 'cosine':\n",
    "        sim = similarity_matrix_cosine(train_ratings)\n",
    "    elif sim_measure.lower() == 'knn':\n",
    "        sim = similarity_matrix_knn(train_ratings, k=k, dim=dim)\n",
    "    else:\n",
    "        raise ValueError('Unknown similarity measure {}'\n",
    "                         .format(sim_measure))\n",
    "    \n",
    "    # Combine the regular similarity and the genre similarity\n",
    "    sim += 0.1 * genre_sim\n",
    "    \n",
    "    pred_ratings = np.zeros((num_test,))\n",
    "    \n",
    "    # Compute error\n",
    "    true_ratings = ratings[test_ind]\n",
    "    for i, (u, m) in enumerate(zip(*test_ind)):\n",
    "        pred_ratings[i] = get_rating(u, m, train_ratings, sim)\n",
    "    \n",
    "    pred_ratings = pred_ratings.clip(1, 5)\n",
    "    return RMSE(true_ratings, pred_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# R = true_ratings[:1500, :3000]\n",
    "R = true_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 11s, sys: 3.71 s, total: 2min 15s\n",
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97799486945741843"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_collaborative_filtering_with_genres(ratings=R, p=0.2, sim_measure='cosine', k=40, top_k=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 1.76 s, total: 2min 1s\n",
      "Wall time: 2min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97446782978933677"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_collaborative_filtering(ratings=R, p=0.2, sim_measure='cosine', k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
