{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from lmafit import lmafit_mc_adp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INVALID = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(A, B):\n",
    "    '''Intesection over Union'''\n",
    "    return float(len(A & B)) / len(A | B)\n",
    "\n",
    "def RMSE(x, y):\n",
    "    assert(x.shape == y.shape)\n",
    "    return np.linalg.norm(x - y) / np.sqrt(x.shape[0])\n",
    "\n",
    "def similarity_matrix(X, sim_measure):\n",
    "    dist = scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(X, sim_measure))\n",
    "    dist[np.isnan(dist)] = 0.0\n",
    "    return 1 - dist\n",
    "\n",
    "def similarity_matrix_cosine(X):\n",
    "    '''\n",
    "    :param X: Ratings matrix. X[i, j] represents the rating of user i for item j.    \n",
    "    :return: n x n cosine similarity matrix\n",
    "    '''\n",
    "    return similarity_matrix(X, 'cosine')\n",
    "\n",
    "def similarity_matrix_knn(X, k, dim=2):\n",
    "    '''\n",
    "    :param X: Ratings matrix. X[i, j] represents the rating of user i for item j.    \n",
    "    :return: n x n KNN similarity matrix\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    if k > n:\n",
    "        raise IndexError('Only {} points, cannot have {} neighbors'\n",
    "                         .format(n, k))\n",
    "    sim = np.zeros((n, n))\n",
    "    dist = spatial.distance_matrix(X, X, dim)\n",
    "    for i in range(n):\n",
    "        # ind is the indices of the closest k points to point i\n",
    "        ind = np.argpartition(dist[i], -k)[:k]\n",
    "        sim[i, ind] = 1.0 / k\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rating(user_id, movie_id, ratings, sim):\n",
    "    n = ratings.shape[0]\n",
    "    sim_values = sim[user_id, :]\n",
    "    movie_ratings = ratings[:, movie_id]\n",
    "    \n",
    "    # Use only valid ratings\n",
    "    valid_ind = movie_ratings != INVALID\n",
    "    sim_values = sim_values[valid_ind]\n",
    "    movie_ratings = movie_ratings[valid_ind]\n",
    "    pred_rating = sim_values.dot(movie_ratings)\n",
    "    total = sim_values.sum()\n",
    "    return pred_rating / total if total > 0 else pred_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_collaborative_filtering(ratings, p, sim_measure='cosine', k=5, dim=2):\n",
    "    '''\n",
    "    :param ratings: Ratings matrix, where ratings[i][j] represents \n",
    "    user i's rating for movie j.\n",
    "    :param sim_measure: Similarity measure to use\n",
    "    :param p: Fraction of data to use as test-set\n",
    "    :param k: In case of kNN, value of k to use\n",
    "    :param dim: In case of kNN, value of dim to use\n",
    "    \n",
    "    :return: RMSE error of predictions\n",
    "    '''\n",
    "    # Get test indices\n",
    "    valid_ind = np.where(ratings != INVALID)\n",
    "    N = valid_ind[0].shape[0]\n",
    "    test_subset = np.random.choice(np.arange(N), int(p * N), replace=False)\n",
    "    test_ind = valid_ind[0][test_subset], valid_ind[1][test_subset]\n",
    "    num_test = test_subset.shape[0]\n",
    "    \n",
    "    # Make the test indices invalid\n",
    "    train_ratings = np.array(ratings)\n",
    "    train_ratings[test_ind] = INVALID\n",
    "\n",
    "    # Compute similarity matrix\n",
    "    sim = similarity_matrix(train_ratings, sim_measure.lower())\n",
    "    pred_ratings = np.zeros((num_test,))\n",
    "    \n",
    "    # Compute error\n",
    "    true_ratings = ratings[test_ind]\n",
    "    for i, (u, m) in enumerate(zip(*test_ind)):\n",
    "        pred_ratings[i] = get_rating(u, m, train_ratings, sim)\n",
    "    \n",
    "    pred_ratings = pred_ratings.clip(1, 5)\n",
    "    return RMSE(true_ratings, pred_ratings)\n",
    "\n",
    "\n",
    "def test_matrix_completion(ratings, p, k):\n",
    "    '''\n",
    "    :param ratings: Ratings matrix, where ratings[i][j] represents \n",
    "    user i's rating for movie j.\n",
    "    :param p: Fraction of data to use as test-set\n",
    "    :param k: Estimated rank of matrix to use for LMaFit\n",
    "    \n",
    "    :return: RMSE error of predictions\n",
    "    '''\n",
    "    # Get test indices\n",
    "    valid_ind = np.where(ratings != INVALID)\n",
    "    N = valid_ind[0].shape[0]\n",
    "    indices = np.arange(N)\n",
    "    np.random.shuffle(indices)\n",
    "    num_test = int(p * N)\n",
    "    test_ind = valid_ind[0][indices[:num_test]], valid_ind[1][indices[:num_test]]\n",
    "    train_ind = valid_ind[0][indices[num_test:]], valid_ind[1][indices[num_test:]]\n",
    "        \n",
    "    # Make the test indices invalid\n",
    "    train_ratings = np.array(ratings)\n",
    "    train_ratings[test_ind] = INVALID\n",
    "    \n",
    "    # Run LMaFit\n",
    "    a, b, _ = lmafit_mc_adp(ratings.shape[0], ratings.shape[1], k, train_ind, ratings[train_ind], None)\n",
    "    completed = a.dot(b)\n",
    "    \n",
    "    # Compute error\n",
    "    completed = completed.clip(1, 5)\n",
    "    return RMSE(ratings[test_ind], completed[test_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "movie_file = \"ml-1m/movies.dat\"\n",
    "m_names = [\"bad_index\", \"Title\", \"Genre\"]\n",
    "movies = pd.read_csv(movie_file, nrows=1000000, header=None, names=m_names, sep=\"::\", engine='python')\n",
    "movie_to_index = dict((m,i) for i,m in zip(movies.index, movies[\"bad_index\"]))\n",
    "movie_to_genre = dict((i,g) for i,g in zip(movies.index, movies[\"Genre\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_to_int = {\n",
    "    'Action' : 0,\n",
    "    'Adventure' : 1,\n",
    "    'Animation' : 2,\n",
    "    'Children\\'s' : 3,\n",
    "    'Comedy' : 4,\n",
    "    'Crime' : 5,\n",
    "    'Documentary' : 6,\n",
    "    'Drama' : 7,\n",
    "    'Fantasy' : 8,\n",
    "    'Film-Noir' : 9, \n",
    "    'Horror' : 10,\n",
    "    'Musical' : 11,\n",
    "    'Mystery' : 12,\n",
    "    'Romance' : 13,\n",
    "    'Sci-Fi' : 14,\n",
    "    'Thriller' : 15,\n",
    "    'War' : 16,\n",
    "    'Western' : 17, \n",
    "}\n",
    "NUM_GENRES = 18\n",
    "\n",
    "def get_genres_for_movie(movie, curr):\n",
    "    inds = [genre_to_int[genre] for genre in movie_to_genre[movie].split('|')]\n",
    "    for i in inds:\n",
    "        curr[i] += 1\n",
    "    return curr\n",
    "\n",
    "def get_top_k_genres_for_user(mat, user, k, return_prefs=False):\n",
    "    movies = mat[user]\n",
    "    genre_prefs = np.zeros(len(genre_to_int))\n",
    "    average_rating = movies[np.nonzero(movies)].mean()\n",
    "    for i, movie in enumerate(movies):\n",
    "        if movie > average_rating:\n",
    "            genre_prefs = get_genres_for_movie(i, genre_prefs)\n",
    "    if return_prefs:\n",
    "        return np.flip(np.sort(genre_prefs))[:k], np.flip(np.argsort(genre_prefs), axis=0)[:k]\n",
    "    else:\n",
    "        return np.flip(np.argsort(genre_prefs), axis=0)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_similarity_matrix_by_overlap(X, top_k):\n",
    "    '''\n",
    "    :param X: Ratings matrix. X[i, j] represents the rating of user i for item j.    \n",
    "    :param top_k: Top-k genres will be considered\n",
    "    :return: n x n genre similarity matrix\n",
    "    '''\n",
    "    n = X.shape[0]  # Number of users\n",
    "    genre_ratings = np.zeros((NUM_GENRES, n, n), dtype=np.bool)\n",
    "    for u in range(n):\n",
    "        best_genres = get_top_k_genres_for_user(X, u, top_k)\n",
    "        genre_ratings[best_genres, u, :] = True\n",
    "\n",
    "    # Now, genre_ratings[i, u, :] == True iff user u has genre i in their top-k genres\n",
    "    # overlap_by_genre[i, u, v] == True iff users u and v both have genre i in their top-k genres\n",
    "    overlap_by_genre = np.logical_and(genre_ratings, genre_ratings.transpose((0, 2, 1)))\n",
    "    assert(overlap_by_genre.shape == (NUM_GENRES, n, n))\n",
    "\n",
    "    return overlap_by_genre.sum(axis=0)\n",
    "\n",
    "def matrix_completion_by_genres(X, top_k=3):\n",
    "    '''\n",
    "    :param X: Ratings matrix. X[i, j] represents the rating of user i for item j.    \n",
    "    :param top_k: Top-k genres will be considered\n",
    "    :return: n x p matrix, with predicted values for movie ratings for each user\n",
    "    using info about genres a user likes\n",
    "    '''\n",
    "    completed = np.zeros(X.shape)\n",
    "    \n",
    "    num_users, num_movies = X.shape\n",
    "    user_genres = [set(get_top_k_genres_for_user(X, u, k=top_k)) for u in range(num_users)]\n",
    "    movie_genres = [{genre_to_int[g] for g in movie_to_genre[m].split('|')} for m in range(num_movies)]\n",
    "    \n",
    "    for u in range(num_users):\n",
    "        for m in range(num_movies):\n",
    "            completed[u, m] = 3.0 + 2.0 * IOU(user_genres[u], movie_genres[m])\n",
    "    return completed\n",
    "\n",
    "# def rate_movies_by_user_history(X, indices, top_k=3):\n",
    "#     '''\n",
    "#     :param X: Ratings matrix. X[i, j] represents the rating of user i for item j.    \n",
    "#     :param top_k: Top-k genres will be considered\n",
    "#     :return: Returns overlap values for users and movies provided in indices\n",
    "#     '''\n",
    "    \n",
    "#     num_users, num_movies = X.shape\n",
    "#     user_genres = [set(get_top_k_genres_for_user(X, u, k=top_k)) for u in range(num_users)]\n",
    "#     movie_genres = [{genre_to_int[g] for g in movie_to_genre[m].split('|')} for m in range(num_movies)]\n",
    "#     overlap = []\n",
    "#     for u, m in zip(indices[0], indices[1]):\n",
    "#         overlap.append(IOU(user_genres[u], movie_genres[m]))\n",
    "    \n",
    "#     return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_genre_based_matrix_completion(ratings, p, top_k=3):\n",
    "    '''\n",
    "    :param ratings: Ratings matrix, where ratings[i][j] represents \n",
    "    user i's rating for movie j.\n",
    "    :param p: Fraction of data to use as test-set\n",
    "    \n",
    "    :return: RMSE error of predictions\n",
    "    '''\n",
    "    # Get test indices\n",
    "    valid_ind = np.where(ratings != INVALID)\n",
    "    N = valid_ind[0].shape[0]\n",
    "    indices = np.arange(N)\n",
    "    np.random.shuffle(indices)\n",
    "    num_test = int(p * N)\n",
    "    test_ind = valid_ind[0][indices[:num_test]], valid_ind[1][indices[:num_test]]\n",
    "    train_ind = valid_ind[0][indices[num_test:]], valid_ind[1][indices[num_test:]]\n",
    "        \n",
    "    # Make the test indices invalid\n",
    "    train_ratings = np.array(ratings)\n",
    "    train_ratings[test_ind] = INVALID\n",
    "    \n",
    "    # Run LMaFit\n",
    "    completed = matrix_completion_by_genres(X=ratings, top_k=top_k)\n",
    "    \n",
    "    # Compute error\n",
    "    completed = completed.clip(1, 5)\n",
    "    return RMSE(ratings[test_ind], completed[test_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_collaborative_filtering_with_genre_bias(ratings, p, bias, sim_measure='cosine', top_k=3):\n",
    "    '''\n",
    "    :param ratings: Ratings matrix, where ratings[i][j] represents \n",
    "    user i's rating for movie j.\n",
    "    :param sim_measure: Similarity measure to use\n",
    "    :param p: Fraction of data to use as test-set\n",
    "    :param top_k: Top-k genres will be considered\n",
    "    \n",
    "    :return: RMSE error of predictions\n",
    "    '''\n",
    "    # Get test indices\n",
    "    valid_ind = np.where(ratings != INVALID)\n",
    "    N = valid_ind[0].shape[0]\n",
    "    indices = np.arange(N)\n",
    "    np.random.shuffle(indices)\n",
    "    num_test = int(p * N)\n",
    "    test_ind = valid_ind[0][indices[:num_test]], valid_ind[1][indices[:num_test]]\n",
    "    train_ind = valid_ind[0][indices[num_test:]], valid_ind[1][indices[num_test:]]\n",
    "        \n",
    "    # Make the test indices invalid\n",
    "    train_ratings = np.array(ratings)\n",
    "    train_ratings[test_ind] = INVALID\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    sim = similarity_matrix(train_ratings, sim_measure.lower())\n",
    "    \n",
    "    # Run content based matrix completion\n",
    "#     overlap = rate_movies_by_user_history(train_ratings, indices=test_ind, top_k=top_k)\n",
    "\n",
    "    pred_ratings = np.zeros((num_test,))\n",
    "    \n",
    "    # Compute error\n",
    "    true_ratings = ratings[test_ind]\n",
    "    for i, (u, m) in enumerate(zip(*test_ind)):\n",
    "        pred_ratings[i] = get_rating(u, m, train_ratings, sim)\n",
    "        \n",
    "        user_genres = set(get_top_k_genres_for_user(train_ratings, u, k=top_k))\n",
    "        movie_genres = {genre_to_int[g] for g in movie_to_genre[m].split('|')}\n",
    "        if len(user_genres & movie_genres) > 0:\n",
    "            pred_ratings[i] += bias\n",
    "        else:\n",
    "            pred_ratings[i] -= bias\n",
    "    \n",
    "    pred_ratings = pred_ratings.clip(1, 5)\n",
    "    return RMSE(true_ratings, pred_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_collaborative_filtering_with_genre_similarity(ratings, p, bias, sim_measure='cosine', top_k=3):\n",
    "    '''\n",
    "    :param ratings: Ratings matrix, where ratings[i][j] represents \n",
    "    user i's rating for movie j.\n",
    "    :param sim_measure: Similarity measure to use\n",
    "    :param p: Fraction of data to use as test-set\n",
    "    :param top_k: Top-k genres will be considered\n",
    "    \n",
    "    :return: RMSE error of predictions\n",
    "    '''\n",
    "    # Get test indices\n",
    "    valid_ind = np.where(ratings != INVALID)\n",
    "    N = valid_ind[0].shape[0]\n",
    "    test_subset = np.random.choice(np.arange(N), int(p * N), replace=False)\n",
    "    test_ind = valid_ind[0][test_subset], valid_ind[1][test_subset]\n",
    "    num_test = test_subset.shape[0]\n",
    "    \n",
    "    # Make the test indices invalid\n",
    "    train_ratings = np.array(ratings)\n",
    "    train_ratings[test_ind] = INVALID\n",
    "    \n",
    "    # Compute the genre similarity matrix\n",
    "    genre_sim = genre_similarity_matrix_by_overlap(train_ratings, top_k=top_k)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    sim = similarity_matrix(train_ratings, sim_measure.lower())\n",
    "\n",
    "    # Combine the regular similarity and the genre similarity\n",
    "    sim += bias * genre_sim\n",
    "    \n",
    "    pred_ratings = np.zeros((num_test,))\n",
    "    \n",
    "    # Compute error\n",
    "    true_ratings = ratings[test_ind]\n",
    "    for i, (u, m) in enumerate(zip(*test_ind)):\n",
    "        pred_ratings[i] = get_rating(u, m, train_ratings, sim)\n",
    "    \n",
    "    pred_ratings = pred_ratings.clip(1, 5)\n",
    "    return RMSE(true_ratings, pred_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_ratings = np.load('1M_ratings_np.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_values = [0.2, 0.4, 0.6, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_measures = ['cosine', 'hamming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cosine': {0.8: 0.98926427214983281, 0.6: 0.97654606173502456, 0.4: 0.97513725400336693, 0.2: 0.97344218358250245}, 'hamming': {0.8: 0.98834014694141203, 0.6: 0.9824942782005992, 0.4: 0.97944235822234826, 0.2: 0.97906590044665009}}\n"
     ]
    }
   ],
   "source": [
    "regular_errors = {s: {} for s in sim_measures}\n",
    "for sim_measure in sim_measures:\n",
    "    for p in p_values:\n",
    "        err = test_collaborative_filtering(ratings=true_ratings, p=p, sim_measure=sim_measure)\n",
    "        regular_errors[sim_measure][p] = err\n",
    "\n",
    "print(regular_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_errors_by_k = {}\n",
    "# for k in [5, 10, 50, 100, 500, 1000]:\n",
    "#     err = test_collaborative_filtering(ratings=true_ratings, p=0.5, sim_measure='knn', k=k)\n",
    "#     knn_errors_by_k[k] = err\n",
    "\n",
    "# print(sorted(knn_errors_by_k.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_values = [0.0, 0.1, 0.2, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cosine', 0.2, 0.0, 0.97424677714293983)\n",
      "('cosine', 0.2, 0.1, 0.97528379695451017)\n",
      "('cosine', 0.2, 0.2, 0.97586986886153404)\n",
      "('cosine', 0.2, 0.5, 0.97395946019486723)\n",
      "('cosine', 0.2, 1.0, 0.97573981350137895)\n",
      "('cosine', 0.4, 0.0, 0.97502402984374115)\n",
      "('cosine', 0.4, 0.1, 0.97567241474729272)\n",
      "('cosine', 0.4, 0.2, 0.97664830674056802)\n",
      "('cosine', 0.4, 0.5, 0.97583035448977051)\n",
      "('cosine', 0.4, 1.0, 0.97722370567660821)\n",
      "('cosine', 0.6, 0.0, 0.97690866143266852)\n",
      "('cosine', 0.6, 0.1, 0.97809897161149428)\n",
      "('cosine', 0.6, 0.2, 0.98023276137296322)\n",
      "('cosine', 0.6, 0.5, 0.97842288848229841)\n",
      "('cosine', 0.6, 1.0, 0.97964691547759775)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: Mean of empty slice.\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cosine', 0.8, 0.0, 0.98907491599525221)\n",
      "('cosine', 0.8, 0.1, 0.98551005983145734)\n",
      "('cosine', 0.8, 0.2, 0.98596535251948858)\n",
      "('cosine', 0.8, 0.5, 0.98633699060636137)\n",
      "('cosine', 0.8, 1.0, 0.9870132275275596)\n",
      "('hamming', 0.2, 0.0, 0.97807946757195763)\n",
      "('hamming', 0.2, 0.1, 0.98089461093263264)\n",
      "('hamming', 0.2, 0.2, 0.97774153743158299)\n",
      "('hamming', 0.2, 0.5, 0.97674293944893231)\n",
      "('hamming', 0.2, 1.0, 0.97545973243304529)\n",
      "('hamming', 0.4, 0.0, 0.97931573170801023)\n",
      "('hamming', 0.4, 0.1, 0.97980361751011036)\n",
      "('hamming', 0.4, 0.2, 0.97940904442174903)\n",
      "('hamming', 0.4, 0.5, 0.97959297262592959)\n",
      "('hamming', 0.4, 1.0, 0.97880131895315114)\n",
      "('hamming', 0.6, 0.0, 0.98168463490313251)\n",
      "('hamming', 0.6, 0.1, 0.98171775584710774)\n",
      "('hamming', 0.6, 0.2, 0.98212523619453251)\n",
      "('hamming', 0.6, 0.5, 0.98045052470104177)\n",
      "('hamming', 0.6, 1.0, 0.98116246024004983)\n",
      "('hamming', 0.8, 0.0, 0.98791330822347079)\n",
      "('hamming', 0.8, 0.1, 0.9880916744826943)\n",
      "('hamming', 0.8, 0.2, 0.98704649999775818)\n",
      "('hamming', 0.8, 0.5, 0.98719065796012129)\n",
      "('hamming', 0.8, 1.0, 0.98634714338073992)\n",
      "{'cosine': {0.8: {0.0: 0.98907491599525221, 0.5: 0.98633699060636137, 0.2: 0.98596535251948858, 0.1: 0.98551005983145734, 1.0: 0.9870132275275596}, 0.6: {0.0: 0.97690866143266852, 0.5: 0.97842288848229841, 0.2: 0.98023276137296322, 0.1: 0.97809897161149428, 1.0: 0.97964691547759775}, 0.4: {0.0: 0.97502402984374115, 0.5: 0.97583035448977051, 0.2: 0.97664830674056802, 0.1: 0.97567241474729272, 1.0: 0.97722370567660821}, 0.2: {0.0: 0.97424677714293983, 0.5: 0.97395946019486723, 0.2: 0.97586986886153404, 0.1: 0.97528379695451017, 1.0: 0.97573981350137895}}, 'hamming': {0.8: {0.0: 0.98791330822347079, 0.5: 0.98719065796012129, 0.2: 0.98704649999775818, 0.1: 0.9880916744826943, 1.0: 0.98634714338073992}, 0.6: {0.0: 0.98168463490313251, 0.5: 0.98045052470104177, 0.2: 0.98212523619453251, 0.1: 0.98171775584710774, 1.0: 0.98116246024004983}, 0.4: {0.0: 0.97931573170801023, 0.5: 0.97959297262592959, 0.2: 0.97940904442174903, 0.1: 0.97980361751011036, 1.0: 0.97880131895315114}, 0.2: {0.0: 0.97807946757195763, 0.5: 0.97674293944893231, 0.2: 0.97774153743158299, 0.1: 0.98089461093263264, 1.0: 0.97545973243304529}}}\n"
     ]
    }
   ],
   "source": [
    "genre_sim_errors = {s: {p: {} for p in p_values} for s in sim_measures}\n",
    "for sim_measure in sim_measures:\n",
    "    for p in p_values:\n",
    "        for bias in bias_values:\n",
    "            err = test_collaborative_filtering_with_genre_similarity(true_ratings, p=p, bias=bias, \n",
    "                                                                     sim_measure=sim_measure, top_k=3)\n",
    "            genre_sim_errors[sim_measure][p][bias] = err\n",
    "            print(sim_measure, p, bias, err)\n",
    "\n",
    "print(genre_sim_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cosine', 0.2, 0.0, 0.97427866160920806)\n",
      "('cosine', 0.2, 0.1, 0.97456440362138674)\n",
      "('cosine', 0.2, 0.2, 0.98539382425615707)\n",
      "('cosine', 0.2, 0.5, 1.0751417958149996)\n",
      "('cosine', 0.2, 1.0, 1.3476818237388124)\n",
      "('cosine', 0.4, 0.0, 0.97602871369402056)\n",
      "('cosine', 0.4, 0.1, 0.97580397792675599)\n",
      "('cosine', 0.4, 0.2, 0.98895492341641311)\n",
      "('cosine', 0.4, 0.5, 1.0826321582875829)\n",
      "('cosine', 0.4, 1.0, 1.3494705451767766)\n",
      "('cosine', 0.6, 0.0, 0.9761838825072221)\n",
      "('cosine', 0.6, 0.1, 0.97890604728191)\n",
      "('cosine', 0.6, 0.2, 0.99196658616061817)\n",
      "('cosine', 0.6, 0.5, 1.0842658092717246)\n",
      "('cosine', 0.6, 1.0, 1.3509185073824312)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: Mean of empty slice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cosine', 0.8, 0.0, 0.98917766250886174)\n",
      "('cosine', 0.8, 0.1, 0.99168909240677294)\n",
      "('cosine', 0.8, 0.2, 1.0029189692136242)\n",
      "('cosine', 0.8, 0.5, 1.0924770824809111)\n",
      "('cosine', 0.8, 1.0, 1.3553654836142701)\n",
      "('hamming', 0.2, 0.0, 0.98047346863069318)\n",
      "('hamming', 0.2, 0.1, 0.98110097520562045)\n",
      "('hamming', 0.2, 0.2, 0.9912506373156279)\n",
      "('hamming', 0.2, 0.5, 1.0863198100440223)\n",
      "('hamming', 0.2, 1.0, 1.3533256178897426)\n",
      "('hamming', 0.4, 0.0, 0.98029102274205804)\n",
      "('hamming', 0.4, 0.1, 0.98146045357185308)\n",
      "('hamming', 0.4, 0.2, 0.99252719193452676)\n",
      "('hamming', 0.4, 0.5, 1.0876014685731881)\n",
      "('hamming', 0.4, 1.0, 1.351811701184003)\n",
      "('hamming', 0.6, 0.0, 0.98204400590864682)\n",
      "('hamming', 0.6, 0.1, 0.98424387301623384)\n",
      "('hamming', 0.6, 0.2, 0.99697047810155426)\n",
      "('hamming', 0.6, 0.5, 1.0889529431267735)\n",
      "('hamming', 0.6, 1.0, 1.3525186959537132)\n",
      "('hamming', 0.8, 0.0, 0.98780407129400738)\n",
      "('hamming', 0.8, 0.1, 0.99145247563457528)\n",
      "('hamming', 0.8, 0.2, 1.0028417448106515)\n",
      "('hamming', 0.8, 0.5, 1.0921025583397048)\n",
      "('hamming', 0.8, 1.0, 1.3608054689846578)\n",
      "{'cosine': {0.8: {0.0: 0.98917766250886174, 0.5: 1.0924770824809111, 0.2: 1.0029189692136242, 0.1: 0.99168909240677294, 1.0: 1.3553654836142701}, 0.6: {0.0: 0.9761838825072221, 0.5: 1.0842658092717246, 0.2: 0.99196658616061817, 0.1: 0.97890604728191, 1.0: 1.3509185073824312}, 0.4: {0.0: 0.97602871369402056, 0.5: 1.0826321582875829, 0.2: 0.98895492341641311, 0.1: 0.97580397792675599, 1.0: 1.3494705451767766}, 0.2: {0.0: 0.97427866160920806, 0.5: 1.0751417958149996, 0.2: 0.98539382425615707, 0.1: 0.97456440362138674, 1.0: 1.3476818237388124}}, 'hamming': {0.8: {0.0: 0.98780407129400738, 0.5: 1.0921025583397048, 0.2: 1.0028417448106515, 0.1: 0.99145247563457528, 1.0: 1.3608054689846578}, 0.6: {0.0: 0.98204400590864682, 0.5: 1.0889529431267735, 0.2: 0.99697047810155426, 0.1: 0.98424387301623384, 1.0: 1.3525186959537132}, 0.4: {0.0: 0.98029102274205804, 0.5: 1.0876014685731881, 0.2: 0.99252719193452676, 0.1: 0.98146045357185308, 1.0: 1.351811701184003}, 0.2: {0.0: 0.98047346863069318, 0.5: 1.0863198100440223, 0.2: 0.9912506373156279, 0.1: 0.98110097520562045, 1.0: 1.3533256178897426}}}\n"
     ]
    }
   ],
   "source": [
    "genre_bias_errors = {s: {p: {} for p in p_values} for s in sim_measures}\n",
    "for sim_measure in sim_measures:\n",
    "    for p in p_values:\n",
    "        for bias in bias_values:\n",
    "            err = test_collaborative_filtering_with_genre_bias(true_ratings, p=p, bias=bias, \n",
    "                                                               sim_measure=sim_measure, top_k=3)\n",
    "            genre_bias_errors[sim_measure][p][bias] = err\n",
    "            print(sim_measure, p, bias, err)\n",
    "\n",
    "print(genre_bias_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.8: 1.1598655995077276, 0.6: 1.1604394889038228, 0.4: 1.1602779989754564, 0.2: 1.1614843641175545}\n"
     ]
    }
   ],
   "source": [
    "genre_matrix_completion = {}\n",
    "for p in p_values:\n",
    "    err = test_genre_based_matrix_completion(true_ratings, p=p, top_k=3)\n",
    "    genre_matrix_completion[p] = err\n",
    "\n",
    "print(genre_matrix_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
